{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0 - Imports\n",
    "\n",
    "### Run this every time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-02T15:41:31.066998Z",
     "start_time": "2018-05-02T15:41:30.889777Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-05-04T18:59:32.740Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import scipy.io as spio\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import absolute as nabs\n",
    "import matplotlib.pyplot as plt\n",
    "#from pandas.plotting import autocorrelation_plot\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "#from keras.layers import LSTM\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from numpy.linalg import LinAlgError\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "from sklearn.preprocessing import StandardScalar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## 1 - Load, clean, test data\n",
    "\n",
    "### Only need this if you haven't run or if h5 gets corrupted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-03T23:00:41.844667Z",
     "start_time": "2018-05-03T23:00:41.404116Z"
    },
    "code_folding": [
     0
    ],
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def impmat(fname = 'M_processed.mat', writ = True):\n",
    "    ''' import matlab crap, and turn it to pickles (or return panda df)'''\n",
    "    mat = spio.loadmat(fname, squeeze_me=True)\n",
    "    M = mat['M'] \n",
    "    head = ['time','ndc1','ndc2','ndc3',\n",
    "            'Trade_Partner_Name', 'Distribution_Center_State','NDC','Distribution_Center_ID_(IC)',\n",
    "    'Distribution_Center_Zip','Eff_Inv_(EU)','Eff_Inv_(PU)','Qty_Ord_(EU)',\n",
    "            'Qty_Ord_(PU)']\n",
    "    # get rid of ndc 1,2,3 because they're pieces of NCD\n",
    "    # also get rid of purchase units, just use eatable\n",
    "    # also get rid of states and zip code\n",
    "    needed = [0,4,6,7,9,11]\n",
    "    head_adj = [head[i] for i in needed] + [\"year\", \"month\", \"week\"]\n",
    "    data = pd.DataFrame(M, columns=head)\n",
    "    data[\"time\"] = pd.to_datetime(data.time, format='%Y%m%d', errors='coerce')\n",
    "    data[\"year\"] = data.time.dt.year\n",
    "    data[\"month\"] = data.time.dt.month\n",
    "    data[\"week\"] = data.time.dt.week\n",
    "    #data.drop(\"time\", axis=1)\n",
    "    if writ: # h5 allows your variable to be external\n",
    "        dt = pd.HDFStore(\"drugdata.h5\") # don't need to import/export! warning, though: huge\n",
    "        dt['dat'] = data[head_adj] #\n",
    "    return(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-01T19:49:58.492939Z",
     "start_time": "2018-05-01T19:49:58.292410Z"
    },
    "code_folding": [
     0
    ],
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def test_hd5(p = 0, q = 0):\n",
    "    \"\"\"test data and run answers to intro quiz\n",
    "    p is to print head of dataframe\n",
    "    q prints quiz answers\n",
    "    doesn't return anything\n",
    "    mostly for access examples\"\"\"\n",
    "    dt = pd.HDFStore(\"drugdata.h5\")[\"dat\"]\n",
    "\n",
    "    header = dt.columns.tolist()\n",
    "    # thanks @brock\n",
    "    def q1(df):\n",
    "        return(df.Trade_Partner_Name.unique())\n",
    "    \n",
    "    def q2(df):\n",
    "        q2 = df.groupby('Trade_Partner_Name')['Distribution_Center_ID_(IC)'].nunique()\n",
    "        q2max = q2.max()\n",
    "        return(q2[q2 == q2max])\n",
    "    \n",
    "    def q3(df):\n",
    "        q3df = df.loc[df[\"time\"].dt.year == 2011] # can also use dt.month\n",
    "        q3TotalSales = q3df.groupby('NDC')['Qty_Ord_(EU)'].sum()\n",
    "        #print(q3TotalSales)\n",
    "        q3sorted = q3TotalSales.sort_values(ascending = False).head()\n",
    "        return(q3sorted)\n",
    "    \n",
    "    def q4(df):\n",
    "        q4 = df['NDC'].value_counts()\n",
    "        NDCLessThan60 = q4[q4 < 60]\n",
    "        if (NDCLessThan60.size == 0):\n",
    "            return(None)\n",
    "        else:\n",
    "            return(NDCLessThan60.size)\n",
    "        \n",
    "    def q5(df):\n",
    "        q5 =  df.groupby('NDC')['Qty_Ord_(EU)'].std()\n",
    "        q5max = q5.max()\n",
    "        NDCHighestVariance = q5[q5 == q5max]\n",
    "        return(NDCHighestVariance)\n",
    "    \n",
    "    def q6(df):\n",
    "        q6 = df.groupby('NDC')['Qty_Ord_(EU)'].nunique()\n",
    "        q6ZeroDemand = q6[q6 == 0]\n",
    "        if (q6ZeroDemand.size == 0):\n",
    "            return(None)\n",
    "        else:\n",
    "            return(q6ZeroDemand.size)\n",
    "    \n",
    "    if p:\n",
    "        for col in header:\n",
    "            print(dt[col].head())\n",
    "    if q:\n",
    "        answers = [q1(dt), q2(dt), q3(dt), q4(dt), q5(dt), q6(dt)]\n",
    "        for i, ans in enumerate(answers):\n",
    "            try:\n",
    "                print('Question %d'%(i+1),  ans)\n",
    "            except:\n",
    "                print('Question %d'%(i+1) + str(ans))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-03T23:01:04.517008Z",
     "start_time": "2018-05-03T23:00:55.390600Z"
    },
    "collapsed": false,
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "impmat(); # uncomment if never built h5 file\n",
    "#test_hd5(q=1) # add p=1 or q = 1 to print stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-04T08:07:54.061771Z",
     "start_time": "2018-05-04T08:07:54.044750Z"
    },
    "code_folding": [
     0
    ],
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def rem_neg_vals():\n",
    "    ''' if you've just imported from the mat file,\n",
    "    you need to run this to change the neg vals to 0 '''\n",
    "    df = pd.HDFStore(\"drugdata.h5\")[\"dat\"]\n",
    "    # set negative values to 0\n",
    "    df.loc[df['Eff_Inv_(EU)'] < 0,'Eff_Inv_(EU)'] = 0\n",
    "    df.loc[df['Qty_Ord_(EU)'] < 0,'Qty_Ord_(EU)'] = 0\n",
    "    df.loc[df['Eff_Inv_(EU)'].isnull(), 'Eff_Inv_(EU)'] = 0\n",
    "    df.loc[df['Qty_Ord_(EU)'].isnull(), 'Qty_Ord_(EU)'] = 0\n",
    "    #print(df.head())\n",
    "    return(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-04T08:07:58.453260Z",
     "start_time": "2018-05-04T08:07:54.963899Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "rem_neg_vals();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-29T14:00:33.564877Z",
     "start_time": "2018-04-29T14:00:33.545367Z"
    },
    "code_folding": [
     0
    ],
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def weeks():\n",
    "    ''' gives us a list of the weeks as a datetime Series '''\n",
    "    df = pd.HDFStore(\"drugdata.h5\")[\"dat\"]\n",
    "\n",
    "    return(pd.to_datetime(df.time.unique()).sort_values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-16T19:20:15.777685Z",
     "start_time": "2018-04-16T19:20:15.652528Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#weeks();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Utilities\n",
    "### Necessary for the data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-02T15:41:58.744596Z",
     "start_time": "2018-05-02T15:41:58.732581Z"
    },
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sales_exist():\n",
    "    ''' want to check that every week has sales\n",
    "        returns list of drug ids that have data for every year '''\n",
    "    df = pd.HDFStore(\"drugdata.h5\")[\"dat\"]\n",
    "    useless = {}\n",
    "    years = [i for i in range(2007, 2018)]\n",
    "    for drug in df.NDC.unique():\n",
    "        useless[drug] = []\n",
    "    for year in years:\n",
    "        sales = df.loc[df.time.dt.year == year].groupby('NDC')['Qty_Ord_(EU)'].sum()\n",
    "        for drug in df.NDC.unique():\n",
    "            try:\n",
    "                if sales[drug] == 0:\n",
    "                    #print(drug, year) # have 0 sum\n",
    "                    useless[drug].append(year)\n",
    "            except:\n",
    "                #print(\"broke by\", drug, \"in\", year)\n",
    "                useless[drug].append(year) # have NA or something?\n",
    "    not_useless = []\n",
    "    for did in useless.keys():\n",
    "        if not useless[did]:\n",
    "            not_useless.append(did)\n",
    "    return(not_useless)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-02T15:41:59.014934Z",
     "start_time": "2018-05-02T15:41:58.745598Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#sales_exist();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-03T23:11:21.547319Z",
     "start_time": "2018-05-03T23:11:21.188871Z"
    },
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def top_selling(thr, p = 0):\n",
    "    ''' in: minimum contributing percentage threshold\n",
    "        if p, prints number and % of drugs above thr\n",
    "        out: IDs of drugs above thr'''\n",
    "    df = pd.HDFStore(\"drugdata.h5\")[\"dat\"]\n",
    "    ind_total = df.groupby('NDC')['Qty_Ord_(EU)'].sum()\n",
    "    sortsales = ind_total.sort_values(ascending = False)\n",
    "    #print(sortsales)\n",
    "    total = sum(ind_total.values)\n",
    "    perc_total = 100 * sortsales / total\n",
    "    clipped_above_total = perc_total[perc_total > thr]\n",
    "    if p:\n",
    "        print(len(clipped_above_total), sum(clipped_above_total.values))\n",
    "    enough = sales_exist()\n",
    "    final = [i for i in enough if i in clipped_above_total.axes[0]]\n",
    "    #return(clipped_above_total.axes)\n",
    "    return(final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-03T23:11:31.483740Z",
     "start_time": "2018-05-03T23:11:26.796881Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4.0, 7.0, 8.0, 32.0, 55.0, 125.0, 141.0, 145.0, 149.0, 154.0]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_selling(1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-02T15:41:59.399415Z",
     "start_time": "2018-05-02T15:41:59.290279Z"
    },
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def norm_drugs(writ = 0):\n",
    "    ''' returns the data frame with only top ten drugs\n",
    "        and has normed column where ordered EU is normalized with (val-mu)/sigma \n",
    "        writ = 'normed' -> h5 '''\n",
    "    dl = top_selling(1.5)\n",
    "    df = pd.HDFStore(\"drugdata.h5\")[\"dat\"]\n",
    "    df.set_index(\"NDC\", inplace=True) # use drug as index\n",
    "    df = df.loc[dl] # only want drugs in top ten\n",
    "    dfgb = df.groupby('NDC')['Qty_Ord_(EU)']\n",
    "    sd = dfgb.std() # standard deviation for each drug\n",
    "    nm = dfgb.mean() # mean for each drug\n",
    "\n",
    "    normd = pd.DataFrame() # empty DF to hold new one\n",
    "    # couldn't figure out vector without using all the memory :/\n",
    "    for drug in dl:\n",
    "        d_s = df.loc[drug,:] # select only one drug for now\n",
    "        n_s = np.subtract(d_s[\"Qty_Ord_(EU)\"],nm[drug]) # numerator\n",
    "        \n",
    "        n_v = d_s.assign(normed=np.divide(n_s, sd[drug])) # new df for drug\n",
    "        normd = pd.concat([normd, n_v]) # add to return df\n",
    "        \n",
    "    if writ: # should we write this to h5?\n",
    "        df_n = pd.HDFStore(\"drugdata.h5\")\n",
    "        df_n[\"normed\"] = normd\n",
    "    return(normd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-02T15:41:59.566624Z",
     "start_time": "2018-05-02T15:41:59.400416Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#ndf = norm_drugs(1)\n",
    "#print(ndf.head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-04T11:49:26.688049Z",
     "start_time": "2018-05-04T11:49:26.680038Z"
    },
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_x(Y, a, h):\n",
    "    ''' creates lag df \n",
    "        Y is Y vector \n",
    "        a is # lags '''\n",
    "    #cols = ['t-'+str(i) for i in range(1, a+1)]\n",
    "    X = pd.DataFrame()\n",
    "    for i in range(h, a+h):                #makes multi-dimensional input\n",
    "        # each datapoint works off of the past 'a' datapoints \n",
    "        X = pd.concat([X, Y.shift(i)], axis=1)\n",
    "    \n",
    "    return(X[a:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-02T15:41:59.819941Z",
     "start_time": "2018-05-02T15:41:59.712807Z"
    },
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sales(Year):\n",
    "    \"\"\"in: range of dates want studied \n",
    "    want to return the list of sales per date\n",
    "    todo: break up by location if we want\"\"\"\n",
    "    df = pd.HDFStore(\"drugdata.h5\")[\"dat\"]\n",
    "    \n",
    "    sel_drugs = top_selling(1.5) # list of drug ids\n",
    "    dates = df.loc[df.year == Year] # choose only given year\n",
    "    # gives DF of drugs by week; can change to \n",
    "    # ['NDC', 'time', DISTRO_id] if we want later\n",
    "    window = dates.groupby(['NDC', \"time\"])['Qty_Ord_(EU)'].sum()\n",
    "    filt_window = window.loc[sel_drugs] # only want top drugs\n",
    "    return(filt_window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-02T15:41:59.965122Z",
     "start_time": "2018-05-02T15:41:59.820942Z"
    },
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# s2008 = sales(2008)\n",
    "# print(s2008)\n",
    "# s2008[4.][:5]\n",
    "# s08_4 = s2008[4]\n",
    "# print(s08_4[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-02T15:42:00.119315Z",
     "start_time": "2018-05-02T15:41:59.965122Z"
    },
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def smape(f, d):\n",
    "    ''' symmetric mean absolute percentage error\n",
    "    in: vectors f = y_hat, d = y \n",
    "    out: the smape, yo '''\n",
    "    n = len(f)\n",
    "    val = np.sum(nabs(f - d)/(nabs(f) + nabs(d)))\n",
    "    return(val/n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-02T15:42:00.311555Z",
     "start_time": "2018-05-02T15:42:00.120316Z"
    },
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def frame_gen(year):\n",
    "    ''' in: the year starting the frame\n",
    "        out: 2 dfs, 3 years for training and 4th for test'''\n",
    "    window = []\n",
    "    for i in range(3): #4 to match AR model\n",
    "        window.append(sales(year + i))\n",
    "    # make a table of 3 years\n",
    "    window = pd.concat(window)\n",
    "    test_frame = sales(year + 3)\n",
    "    return(window, test_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-02T15:42:00.408677Z",
     "start_time": "2018-05-02T15:42:00.311555Z"
    },
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# a,b = frame_gen(2008)\n",
    "# print(a)\n",
    "# plt.plot(a[4])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 - The meaty bits!\n",
    "### Contains all models: SVR, ARIMA, Neural Network, LASSO, and AR\n",
    "### SVR is prohibitively slow on small datasets, and AR is terrible so both are excluded later\n",
    "### also contains plotting functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-02T15:42:00.539840Z",
     "start_time": "2018-05-02T15:42:00.409678Z"
    },
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_all_year_drug_sales():\n",
    "    #df = pd.HDFStore(\"drugdata.h5\")['normed']\n",
    "    df = pd.HDFStore(\"drugdata.h5\")['dat']\n",
    "\n",
    "    dl = top_selling(1.5)\n",
    "    \n",
    "    for drug in dl:\n",
    "        sub = df.loc[df.NDC == drug]\n",
    "        ndcSales = sub.groupby(\"time\")[\"Qty_Ord_(EU)\"].sum()\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.plot(ndcSales, 'bo')\n",
    "        ax.set(xlabel='Year', ylabel='Extended Units',\n",
    "           title='Total Sales drug ' + str(drug))\n",
    "        ax.grid()\n",
    "        plt.show()\n",
    "        \n",
    "        autocorrelation_plot(ndcSales)\n",
    "        plt.show()\n",
    "        \n",
    "#plot_drug_sales()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-04T00:19:29.441339Z",
     "start_time": "2018-05-04T00:19:29.268122Z"
    },
    "code_folding": [
     0
    ],
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_sel(test, pred, func, d):\n",
    "    ''' helper function to plot stuff\n",
    "        test is Y_test, pred is Y_hat\n",
    "        func = modeler, d = drug ID '''\n",
    "    year = test.index[0].year\n",
    "    plt.close() # need to clear previous plots\n",
    "    #plt.plot(test, label=\"actual\")\n",
    "    test.plot(label=\"actual\")\n",
    "    pred_fix = pd.Series(pred, index=test.index) # problem with the dates not lining up\n",
    "    #plt.plot(pred_fix, label=\"predict\")\n",
    "    err = smape(test, pred)\n",
    "    pred_fix.plot(label=\"predicted\")\n",
    "    plt.xlabel('time (wk)')\n",
    "    plt.ylabel('Extended Units')\n",
    "    plt.title('Predicted vs Actual '+ func + \" on drug \" + str(d) + \" in \" + str(year) + \", sMAPE = \" + str(round(err, 2)))\n",
    "    plt.grid()\n",
    "    plt.legend()#[\"actual\", \"predicted\"])\n",
    "    stri = \"figs/\" +func + str(d) + \"_\" + str(year) + \".pdf\" # save as pdf because it's svg (scales better)\n",
    "    plt.savefig(stri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-04T12:07:01.109114Z",
     "start_time": "2018-05-04T12:07:01.054045Z"
    },
    "code_folding": [],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def SVR_stuff(Y_train, Y_test, h, p=0, a=10):\n",
    "    ''' input: testing and training data \n",
    "        out: support vector regression score(?) '''\n",
    "    scaler = StandardScaler()\n",
    "    \n",
    "    scaler.fit(Y_train)\n",
    "    Y_train = scaler.transform(Y_train)\n",
    "    \n",
    "    scaler.fit(Y_test)\n",
    "    Y_test = scaler.transform(Y_test)\n",
    "    \n",
    "    X_train = make_x(Y_train, a, h)\n",
    "    X_test = make_x(Y_test, a, h)\n",
    "    Y_train = Y_train[a:]\n",
    "    Y_test = Y_test[a:]\n",
    "\n",
    "\n",
    "    ks = [\"rbf\", \"linear\", \"poly\", \"sigmoid\"]    \n",
    "    for k in ks:\n",
    "        print(k)\n",
    "        regr = SVR(kernel = k, C=500)               #creates/fits model\n",
    "        regr.fit(X_train, Y_train)\n",
    "        yhat_trn = regr.predict(X_train)\n",
    "        yhat_tst = regr.predict(X_test)\n",
    "\n",
    "        if p:\n",
    "            plt.plot(Y_train, color='red')\n",
    "            ytr = pd.Series(yhat_trn, index=Y_train.index)\n",
    "            plt.plot(ytr, color='blue')\n",
    "            plt.show()\n",
    "            ytt = pd.Series(yhat_tst, index=Y_test.index)\n",
    "            plt.plot(ytt, color='blue')\n",
    "            plt.plot(Y_test, color='red')\n",
    "            plt.show()\n",
    "            error = smape(ytt, Y_test)              #change to SMAPE?\n",
    "            print(\"Error: \", error)\n",
    "            print(mse(Y_test, ytt))\n",
    "    return(error) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-02T16:57:12.059408Z",
     "start_time": "2018-05-02T16:57:12.047393Z"
    },
    "code_folding": [
     0
    ],
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def ARIMA_stuff(train, test, d, p=0):\n",
    "    \n",
    "    history = [x for x in train]\n",
    "    predictions = []\n",
    "    with warnings.catch_warnings(): #loud arima\n",
    "        warnings.filterwarnings(\"ignore\")\n",
    "        for t in range(len(test)): # only predicting one ahead\n",
    "            model = ARIMA(history, order=(10,1,0))\n",
    "            try: model_fit = model.fit(disp=0)\n",
    "            except (ValueError, LinAlgError): pass\n",
    "            output = model_fit.forecast()\n",
    "            yhat = output[0][0] # i swear, who made this output decision? a list of numpy arrays??\n",
    "            predictions.append(yhat)\n",
    "            obs = test[t]\n",
    "            history.append(obs)\n",
    "            history.pop(0)\n",
    "\n",
    "    err = smape(test, predictions)\n",
    "\n",
    "    if p:\n",
    "        plot_sel(test, predictions, \"ARIMA\", d)\n",
    "    return(err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-02T15:42:00.973382Z",
     "start_time": "2018-05-02T19:41:47.854Z"
    },
    "code_folding": [],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#ARIMA_stuff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-04T11:50:31.452006Z",
     "start_time": "2018-05-04T11:50:31.426974Z"
    },
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def NN_stuff(Y_train, Y_test, d, h, p=0, a = 5):\n",
    "\n",
    "    X_train = make_x(Y_train, a, h)\n",
    "    Y_train = Y_train[a:]\n",
    "\n",
    "    X_test = make_x(Y_test, a, h)\n",
    "    Y_test = Y_test[a:]\n",
    "    \n",
    "    [n, m] = X_train.shape\n",
    "    \n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Dense(5, input_dim = a, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(11, kernel_initializer='normal', activation = 'relu'))\n",
    "   # model.add(Dense(11, kernel_initializer='normal', activation = 'relu'))\n",
    "    model.add(Dense(1, kernel_initializer='normal', activation = 'relu'))\n",
    "    model.compile(loss='mse', optimizer='adam')\n",
    "    \n",
    "    model.fit(X_train, Y_train, epochs = 1000, verbose = 0)\n",
    "    \n",
    "    \n",
    "    yhat_tst = [item[0] for item in model.predict(X_test)]\n",
    "    \n",
    "    if p:\n",
    "        plot_sel(Y_test, yhat_tst, \"NeuralNet\", d)\n",
    "\n",
    "    error = smape(yhat_tst, Y_test)\n",
    "    return(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-02T15:43:58.007680Z",
     "start_time": "2018-05-02T15:43:58.000671Z"
    },
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lasso_stuff(Y_train, Y_test, d, p = 0, a = 10):\n",
    "\n",
    "    X_train = make_x(Y_train, a)\n",
    "    X_test = make_x(Y_test, a)\n",
    "    Y_train = Y_train[a:]\n",
    "    Y_test = Y_test[a:]\n",
    "\n",
    "    regr = LassoCV()               #creates/fits model\n",
    "    regr.fit(X_train, Y_train)\n",
    "    yhat_trn = regr.predict(X_train)\n",
    "    yhat_tst = regr.predict(X_test)\n",
    "    ytt = pd.Series(yhat_tst, index=Y_test.index)\n",
    "    error = smape(ytt, Y_test) \n",
    "    if p:\n",
    "        plot_sel(Y_test, yhat_tst, \"LASSO\", d)\n",
    "    return(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-02T15:44:01.802423Z",
     "start_time": "2018-05-02T15:44:01.800421Z"
    },
    "code_folding": [],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#lasso_stuff(1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-02T15:44:02.044727Z",
     "start_time": "2018-05-02T15:44:02.034714Z"
    },
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Auto_regress(drug, X, lag_size, plots=0):\n",
    "    ''' need model for each drug id; maybe pass in main?\n",
    "        test data, train data\n",
    "        lag is number of previous vars\n",
    "        but, model chooses lag size?? '''\n",
    "    # sauce: https://machinelearningmastery.com/autoregression-models-time-series-forecasting-python/\n",
    "    #from sklearn.svm import SVR\n",
    "    from statsmodels.tsa.ar_model import AR\n",
    "    \n",
    "    # at this point all drugs have all data for all years, so we can generalize\n",
    "    X_trn = X[drug].values[:157] # first 3 years\n",
    "    X_tst = X[drug].values[157:] # next\n",
    "    if plots:\n",
    "        from statsmodels.graphics.tsaplots import plot_acf\n",
    "        plot_acf(X_trn, lags=lag_size)\n",
    "        plt.show()\n",
    "    model = AR(X_trn)\n",
    "    fits = model.fit()\n",
    "    print(\"Thetas:\", fits.params)\n",
    "    print(\"lag:\", fits.k_ar)\n",
    "    \n",
    "    pred = fits.predict(start=len(X_trn), end=len(X_trn)+len(X_tst)-1, dynamic=True)\n",
    "    from sklearn.metrics import mean_squared_error as mse\n",
    "    print(\"MSE:\", mse(X_tst, pred))\n",
    "    plt.plot(X_tst)\n",
    "    plt.plot(pred, color='red')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-04T12:00:24.026746Z",
     "start_time": "2018-05-04T12:00:23.974681Z"
    },
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def LSTM_stuff(Y_train, Y_test, d, h, p=0, a = 5):\n",
    "    from keras.layers import LSTM\n",
    "    X_train = make_x(Y_train, a, h)\n",
    "    Y_train = Y_train[a:]\n",
    "\n",
    "    X_test = make_x(Y_test, a, h)\n",
    "    Y_test = Y_test[a:]\n",
    "    \n",
    "    [n, m] = X_train.shape\n",
    "    X_train = np.asarray(X_train)\n",
    "    X_test = np.asarray(X_test)\n",
    "    X_train = np.reshape(X_train, (X_train.shape[0], 1, X_train.shape[1]))\n",
    "    X_test = np.reshape(X_test, (X_test.shape[0], 1, X_test.shape[1]))\n",
    "\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(LSTM(5, input_shape=(1, 5), activation = 'relu'))\n",
    "    model.add(Dense(11, kernel_initializer='normal', activation = 'relu'))\n",
    "    model.add(Dense(1, kernel_initializer='normal', activation = 'relu'))\n",
    "    model.compile(loss='mse', optimizer='adam')\n",
    "    \n",
    "    model.fit(X_train, Y_train, epochs = 1000, verbose = 0)\n",
    "    \n",
    "    \n",
    "    yhat_tst = [item[0] for item in model.predict(X_test)]\n",
    "    \n",
    "    if p:\n",
    "        plot_sel(Y_test, yhat_tst, \"LSTM\", d)\n",
    "\n",
    "    error = smape(yhat_tst, Y_test)\n",
    "    return(error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Putting it all together\n",
    "### main() runs 3 models, and writes to file 'best.txt' where each model and error are listed\n",
    "### get_some_tables plots the models with sMAPE below threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-04T12:01:24.604471Z",
     "start_time": "2018-05-04T12:01:24.448276Z"
    },
    "code_folding": [
     0
    ],
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def main(file):\n",
    "    dt = pd.HDFStore(\"drugdata.h5\")[\"dat\"]\n",
    "    # we are gonna add 3 to this. only want full years too, why not.\n",
    "    spread = [i for i in range(2008, 2014)]\n",
    "    dlist = top_selling(1.5)\n",
    "    with open(file, \"w\") as f:\n",
    "        for h in range(1, 9):\n",
    "            for year in spread: # sliding window for analysis\n",
    "                [trn, tst] = frame_gen(year) # get train and test data for given time\n",
    "                for drug in dlist:\n",
    "\n",
    "                    tn = trn[drug]\n",
    "                    tt = tst[drug]\n",
    "                    #seth = svr_stuff(tst, trn)\n",
    "                    collin = NN_stuff(tt, tn, drug)\n",
    "                    #jack2 = lasso_stuff(tn, tt, drug)\n",
    "                    jack = ARIMA_stuff(tn, tt, drug)\n",
    "\n",
    "                    which = [collin, jack2, collin2]\n",
    "                    who = [\"NN\", \"LASSO\", \"LSTM\"]\n",
    "                    best_for_year = who[which.index(min(which))]\n",
    "                    #print(\"The best for\", year, \"is\", best_for_year, \"on drug\", drug)\n",
    "                    outstr_all = str(year)+\",\"+str(drug)+\",0\"+\",\"+str(collin)+ h + \"\\n\"\n",
    "                    outstr_all += str(year)+\",\"+str(drug)+\",1\"+\",\"+str(jack)+ h + \"\\n\"\n",
    "                    outstr_all += str(year)+\",\"+str(drug)+\",2\"+\",\"+str(jack2)+ h + \"\\n\"\n",
    "                    outstr_all += str(year)+\",\"+str(drug)+\",3\"+\",\"+str(collin2)+ h + \"\\n\"\n",
    "                    #outstr = str(year)+\",\"+str(drug)+\",\"+str(best_for_year)+\",\"+str(min(which))+\"\\n\"\n",
    "                    f.write(outstr_all)\n",
    "        f.closed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-03T00:47:19.782111Z",
     "start_time": "2018-05-02T22:37:02.330005Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#main(\"best.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-04T08:43:35.345455Z",
     "start_time": "2018-05-04T08:21:45.590212Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "main(\"LSTM.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-04T00:15:31.303658Z",
     "start_time": "2018-05-04T00:15:31.029316Z"
    },
    "code_folding": [
     0
    ],
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_some_tables(thr=.1):\n",
    "    #func = {\"collin\":NN_stuff, \"jack\":ARIMA_stuff, \"jack again\":lasso_stuff}\n",
    "    func = {\"0\":NN_stuff, \"1\":ARIMA_stuff, \"2\":lasso_stuff}\n",
    "    # what do we want? Averages, counts, etc??\n",
    "    # file is year, drug ID, function ID, SMAPE\n",
    "    with open(\"best.txt\",\"r\") as f:\n",
    "        howmany = [0, 0, 0] # histogram\n",
    "        c_year = 0\n",
    "        for line in f:\n",
    "            l = line.split(\",\")\n",
    "            err = float(l[-1]) # get smape\n",
    "            if err < thr:\n",
    "                year, drug = int(l[0])+3, int(float(l[1]))\n",
    "                if c_year != year: # this bit is slow, don't need to update every time\n",
    "                    [trn, tst] = frame_gen(year)\n",
    "                    c_year = year\n",
    "                tn = trn[drug]\n",
    "                tt = tst[drug]\n",
    "                func[l[2]](tn, tt, p=1, d=drug) # call the function that has good error\n",
    "            howmany[int(l[2])] += 1\n",
    "        print(howmany)\n",
    "    f.closed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-03T11:50:56.519515Z",
     "start_time": "2018-05-03T11:27:05.583792Z"
    },
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[60, 60, 60]\n"
     ]
    }
   ],
   "source": [
    "get_some_tables()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Testing block, ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-04T08:08:46.861773Z",
     "start_time": "2018-05-04T08:08:30.003700Z"
    },
    "code_folding": [],
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# testing block; this bit is slow-ish\n",
    "[trn, tst] = frame_gen(2008)\n",
    "tn = trn[4]\n",
    "tt = tst[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-04T00:14:03.830313Z",
     "start_time": "2018-05-04T00:14:01.053842Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "maybe = lasso_stuff(tn, tt, 4, p=1)\n",
    "#ars = ARIMA_stuff(tn, tt, 4, p=1)\n",
    "#js = SVR_stuff(tn, tt, 1)\n",
    "#xt = make_x(tn, 10)\n",
    "#cl = NN_stuff(tn, tt, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-04T00:30:36.657383Z",
     "start_time": "2018-05-04T00:30:02.876156Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "[trn, tst] = frame_gen(2011)\n",
    "tn = trn[141]\n",
    "tt = tst[141]\n",
    "cl = NN_stuff(tn, tt, 141, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-04T00:20:28.100665Z",
     "start_time": "2018-05-04T00:19:47.668123Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "[trn, tst] = frame_gen(2011)\n",
    "tn = trn[8]\n",
    "tt = tst[8]\n",
    "cl = NN_stuff(tn, tt, 8, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-04T00:40:02.548769Z",
     "start_time": "2018-05-04T00:37:34.124233Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "[trn, tst] = frame_gen(2012)\n",
    "tn = trn[55]\n",
    "tt = tst[55]\n",
    "cl = LSTM_stuff(tn, tt, 55, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-05-04T16:07:46.132Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rbf\n",
      "Error:  0.1501163549063914\n",
      "91556191551.8\n",
      "linear\n"
     ]
    }
   ],
   "source": [
    "[trn, tst] = frame_gen(2009)\n",
    "tn = trn[7]\n",
    "tt = tst[7]\n",
    "#cl = LSTM_stuff(tn, tt, 7, 1, 1)\n",
    "#sl = SVR_stuff(tn, tt, 1,p=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-04T12:05:18.266557Z",
     "start_time": "2018-05-04T12:05:15.494092Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVR(C=1.0, cache_size=200, coef0=1,\n",
       "  degree=time\n",
       "2012-01-01    4.884240e+05\n",
       "2012-01-08    1.289130e+06\n",
       "2012-01-15    6.178800e+05\n",
       "2012-01-22    1.070820e+06\n",
       "2012-01-29    5.497800e+05\n",
       "2012-02-05    6.108000e+05\n",
       "2012-02-12    9.225300e+05\n",
       "2012-02-19    5.427300e+05\n",
       "2012-02-26    5.446800e+05\n",
       "2012-03-04    5.443200e+05\n",
       "2012-03-11    5.20....507950e+06\n",
       "2012-12-23    2.059950e+06\n",
       "2012-12-30    1.060140e+06\n",
       "Name: Qty_Ord_(EU), dtype: float64,\n",
       "  epsilon=0.1, gamma=1,\n",
       "  kernel=time\n",
       "2009-01-04    9.455940e+05\n",
       "2009-01-11    1.444314e+06\n",
       "2009-01-18    9.904740e+05\n",
       "2009-01-25    9.014340e+05\n",
       "2009-02-01    9.669540e+05\n",
       "2009-02-08    1.541034e+06\n",
       "2009-02-15    1.646004e+06\n",
       "2009-02-22    9.736740e+05\n",
       "2009-03-01    9.095940e+05\n",
       "2009-03-08    9.371940e+05\n",
       "2009-03-15    9.45....749040e+05\n",
       "2011-12-18    1.115544e+06\n",
       "2011-12-25    8.039040e+05\n",
       "Name: Qty_Ord_(EU), dtype: float64,\n",
       "  max_iter=-1, shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
